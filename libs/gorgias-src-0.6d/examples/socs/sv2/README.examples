@title Examples of WP1

@author Neophytos Demetriou (nkd@ucy.ac.cy)
@author Wenjin Lue (lue@soi.city.ac.uk)
@author Antonis Kakas (ack@doc.ic.ac.uk)
@author Nicolas Maudet (maudet@soi.city.ac.uk)
@author Kostas Stathis (stathis@di.unipi.it)

The scenario presented here is an extension of the 'Leaving San Vincenzo'
scenario presented in [1].

==ADAPTABILITY==

Example 1 (Goal Decision -- Suspension/Introduction):

This example demonstrates the suspension of a goal. Due to some change
in the environment, a goal or action may be temporarily suspended  to
give priority to a more preferred goal or action. In particular, a "more
urgent" goal/action might be preferred over a "less urgent" goal/action.

Francisco's computee contains a personality theory on needs and
motivations of the kind discussed in [2] and re-interpreted in [3].
Following the re-interpretation proposed in [3] the computee has its
possible goal decisions separated into five major categories based on the
needs each goal decision contributes to fulfill:  Operational,
Self-benefit, Peer-interaction, Community-interaction, and
Non-utilitarian. See [3] for an explanation.

In our example, Francisco's computee has to take into consideration its
own needs, for example, its operational needs dictate to the computee to
take appropriate action when Francisco's PDA is running out of battery
power. Francisco's computee has also to take into consideration the needs
of Francisco as part of the Peer-interaction motivations, for example,
Francisco's recurring needs include reading daily news stories and, in
this scenario, context-dependent needs like leaving San Vincenzo at
14:00h. Thus, possible goal decisions contributing to the fulfillment of
these needs are encoded in his computee's knowledge-base for goal
decision, in order to allow for the aggregation of news feeds and support
the traveling arrangements.

Goal decisions that contribute to the fulfillment of needs in the
lower-level of the hierarchy are preferred over those that contribute to
needs in the higher-level of the hierarchy. For example, a low-battery
alert from the PDA has higher priority over aggregation of news feeds.
Moreover, goal decisions that contribute to context-dependent needs of
Francisco (like catching a train)  are likely to be ranked higher than
context-independent and recurring needs (like reading of news items). In
other words, a heuristic function that determines the urgency of the
context-dependent need of Francisco to catch the 14:00h train to leave 
San Vincenzo is more urgent than aggregating news feeds on the day of the
departure. However, a low-battery alert from the PDA is always preferred
in order to avoid loosing all the PDA data.

  Behaviour:

  - Leaving San Vincenzo is considered an urgent goal on the departure date
    and thus it is selected over the rest of the goals.

  - Now, suppose that in previous transitions a POI occured which added an
    observation about low-battery from Francisco's PDA. In that case, 
    Francisco's computee prefers to add a low-battery alert as its top-level 
    goal.



    

Example 2 (Goal Decision -- Suspension/Introduction)

After some change in the environment, a goal may be introduced in the sense of
being brought into the foreground due to a change of preferences of the 
computee.

In this example Francisco's computee has an impatient profile of behaviour. The
scenario begins with a GI transition that introduces the goal of leaving San 
Vincenzo. Then, a PI transition introduces a plan for checking out of the hotel
and going to the train station. On route to the station Francisco's computee 
receives  new information (via a POI transition) about a signal failure in the 
Tuscan train network that is causing indefinite delays to trains for San 
Vincenzo.


  Behaviour:

  - After receiving the news about the signal failure that causes delays to
    to trains via a POI transition, the only valid cycle steps are GI, RE, GR.
    The computee by reasoning using the preferences in its cycle theory decides
    to react (via an RE transition) by notifying Francisco's family and company
    about the delay. In the sequel, leaving San Vincenzo is no 
    longer the preferred top level goal -- in the presense of these passive 
    observations, i.e. that there are indefinite train delays, arranging
    a sightseeing tour in Rome ranks higher. This behaviour is consistent with
    the impatient profile of the computee, i.e. as soon as the computee finds
    out that the plan for leaving San Vincenzo is invalidated by the 
    environment prefers to abandon it and execute other goals.



Example 3 (Reactivity using Preference Reasoning):

\comments{
	Reactivity using preference reasoning is beyond the specification in D4
	as it stands at the moment. We include it here to show the possibility
	for future work in this area using the power of the underlying 
	framework as implemented in Gorgias.
}

In trying to achieve the goal of leaving San Vincenzo, Francisco's computee
receives a request (by means of a POI transition) from another computee to
share a taxi. The computee knows that Francisco has a set of preferences for
sharing taxis, i.e.:

o (Level 1: Default) Accept the offer.

o (Level 1: Exception) Reject the offer if there's a single taxi available.

o (Level 2: Default) Reject the offer if there's a single taxi available, and
   Francisco has the required cash.

o (Level 2: Exception) Accept the offer if Francisco has only 1/2 of the 
   required cash.


  Behaviour:

  - If the computee's $KB_0$ concludes that there's a single taxi available,
    and that Francisco has enough cash to pay for a single taxi, then the
    offer is rejected.

  - Otherwise, the offer is accepted.




==HETEROGENEITY==

Example 4 (Cycle Theory Computation -- Same Scenario, Different Profile)

Consider the following scenario: Francisco's computee has the goal of leaving 
San Vincenzo (introduced by a GI transition) and a PI transition introduces
a plan for initiating the checkout process, making the payment, and arranging
transportation from the hotel to the train station. As soon as the computee
executes an action asking for a taxi (via an AE transition), he realizes that
the action failed (it does not get a reply). As shown below, a computee would
exhibit different decisions for the next cycle-step based on the assigned 
profile of behaviour as specified in~\cite{D4}. Note that GI, PI, AE, AOI, 
and PR are the only valid transitions, i.e. only one of these transitions can
follow an AE transition.

  Behaviour:

  - A punctual computee prefers to request a porter (an AE transition) since 
    that action is qualified as urgent by the heuristic selection function 
    $h^u_{AS}$, i.e. its deadline is about to expire, and thus the punctual 
    profile dictates that the execution of an urgent action has higher priority
    than other transitions.

  - A careful computee prefers to revise its plan (a PR transition) in the next
    cycle-step. The heuristic selection function $h^u_{fail}$ is a non-empty
    set due to the fact that asking for a taxi in the previous transition 
    failed. Hence, according to the careful profile of behaviour, a PR
    transition is preferred over other transitions.

  - An impatient computee demotes the AE transition in favor of other 
    transitions (in our example it selects a PR transition). This is a 
    consequence of its profile preferences since there exists an invalidated
    action, i.e. asking for a taxi. 

  - A cautious computee prefers to make the payment (an AE transition) rather
    than request for a porter. Obviously, asking for a porter is not qualified
    since that action's preconditions (computed via means of $h^{pre}_{AS}$ are
    not satisfied, i.e. asking for a taxi did not succeed in the previous step.

  - Clearly, a computee that is both punctual and careful can choose either an
    AE or PR transition. However, by embedding a higher-order priority in our
    cycle theory, we ranked the careful profile as more important in the case
    of a timed out or failed action. Therefore, a PR transition is selected for
    the next cycle step of a computee assigned with this hybrid profile of 
    behaviour.



Example 5 (Interrupt Component)

Consider the previous scenario extended as follows: As soon as the computee
realizes that its last action asking for a taxi (via an AE transition) failed,
new information (introduced via a POI transition) about a signal failure in the
Tuscan train network is causing indefinite delays to trains for San Vincenzo. 
This forces the computee to reconsider its plan of action. Note that GR, RE,
and GI are the only valid transitions that can follow a POI transition.


  Behaviour:

  - The interrupt component is triggered and thus the computee makes the same
    decision no matter what profile of behaviour is assigned. In our example,
    the selected transition for the next cycle-step is for goal revision (GR).

  - Now, suppose that a POI transition is invoked again to introduce a
    request by another computee to share a taxi to the train station. The 
    next cycle-step would be an RE transition since we have deliberately 
    ranked reactivity as preferred in the case of passive observations 
    that require communication acts on behalf of the computee.


Example 6 (Multi-Behaviour)

The computee in this scenario has the cautious pattern of behaviour but also 
prefers to follow a sequence of transitions that allows it to achieve its 
goals in an optimal way with respect to some utility or cost criterion. Hence 
as in the case of the punctual computee where the utility is time, the utility 
function determines preferences amongst alternative choices of transitions.

Our criterion of optimality here is to minimize the number of observations. 
Therefore, 'SI' and 'AOI' transitions are ranked lower than other transitions
as long as there were no failed actions in the previous step. On the other hand
a cautious computee prefers to do a sensing introduction transition over an
action execution transition. Moreover, in this scenario, the computee has 
preferences which depict that being efficient is more important than being
cautious as long as there were no failed actions in the previous steps 
signalled via information asserted by a POI transition. The default in this 
computee's behaviour is to try to execute actions that their preconditions hold
(a subpattern of the cautious profile of behaviour that is not defeated by the 
preferences for being efficient) but does not check that the desired 
effects/postconditions of an action hold after its execution.

The scenario begins with Francisco checking out of the hotel and heading to the
train station. On route to the station, the computee is suppose to order the 
train tickets and make dinner arrangements for Francisco and his wife.

  Behaviour:

  - Ordering the tickets happens via an AE transition, however, the computee
    does not check whether there are any train delays (no train delays is a
    postcondition for ordering the tickets). Thus, it proceeds via another
    AE transition and makes a table reservation for two in a restaurant back
    home. Then, new information about a signal failure in the train network
    that causes indefinite train delays is introduced via a POI transition.
    Since, there is no way that Francisco will make it back to Spain in time,
    the computee cancels the table reservation and informs Francisco about the
    situation  (PR, AE, AE). 

  - Now suppose that, there were no efficiency constraints on the computee, 
    i.e. its only preferences are those in the cautious pattern of behaviour.
    Then, as soon as the computee orders the tickets it does a sensing
    introduction transition which adds the information about the train delays.
    In this case, the computee refrains from making dinner arrangements in the
    next cycle step since that would require Francisco to be back in Spain on 
    time (a precondition).



Example 7 (Multi-Behaviour -- Complete Scenario)

The behaviour part of the cycle theories in the previous examples is obtained
by using the heuristic selection functions, as specified in D4 and other
heuristic criteria to define the behaviour conditions. Each heuristic
corresponds to a criterion of evaluation and hence we need to have ways
to perform, via the cycle theory, a multi-criteria decision in order to
take into account simultaneously a variety of heuristics. This example shows
a complete scenario in which we synthesize the different patterns of 
behaviour in D4 and thus their underlying criteria to get an effective and 
intelligent behaviour of a computee. 

In this scenario, the computee prefers to be punctual when the goals or 
actions to be accomplished have an approaching expiring date. Moreover,
the computee is both cautious and efficient (minimizing the number of
observations) as discussed in the previous example, for convenience we call
this pattern of behaviour as cautious-and-obs-eff. Being cautious-and-obs-eff
is less important than being punctual. This means that the computee might
execute an action without checking if the preconditions hold but for
non-urgent actions the default would be to check the preconditions while at
the same time trying to minimize the sensing actions. Finally, the computee
exhibits an impatient pattern of behaviour that ranks on top of the punctual
or cautious-and-obs-eff preferences.

The goal decision KB is modelled after the one examined in Example 1 while the 
reactivity KB is similar to the one discussed in Example 3. The scenario
begins on the day that Francisco should depart from San Vincenzo.


  Behaviour

  - The computee begins with a GI transition. Upon execution of the GI 
    transition via means of the GD capability the goal of leaving San Vincenzo
    is preferred and thus it is selected to be added in the list of goals in
    the current state of the computee. Initially, the Goals were empty so this
    is the only goal in the current state.

  - In the sequel, a PI transition is selected with an input of the only goal 
    in the current state. This is due to the fact that most core selection
    functions do not qualify other transitions, e.g. the action selection
    function returns the empty set so the enabling conditions for AE are not 
    satisfied. Upon execution of the PI transition the planning capability 
    returns a list of actions to satisfy the given goal, i.e. initiating the 
    checkout process, making the payment, arranging transportation from the
    hotel to the train station, ordering tickets and making table reservations
    for the evening.

  - The next three cycle steps involve action executions (AE,AE,AE) for calling
    a taxi, making the payment and requesting a porter. None of these actions
    had any preconditions so the preferences of the punctual pattern of 
    behaviour were the only ones triggered (i.e. none of the preferences for 
    cautious-and-obs-eff were triggered). However, requesting a porter had
    a postcondition for checking that the porter actually arrived.

  - No longer are there any urgent actions or goals (there is no rush to order 
    the tickets since there is plenty of time until they reach the train
    station) and thus for the next cycle step an AOI transition is selected in
    order to check whether the porter arrived or not.

    That last action observation introduction was a blocking action, i.e. it 
    requires input from Francisco in order to continue. Francisco, then, 
    presses "yes" when the porter is in the room or "no" when the porter is too
    late. [We make the simplifying assumption that the porter will go to 
    Francisco's room only when the taxi arrives at the hotel. However, this 
    could be implemented as a conditional request, i.e. "we need a porter when 
    the taxi is here"] Suppose that the porter answered the call in prompt
    time (and thus that signified that the taxi arrived) and that the 
    action observation was added in the computee's KB0.

  - While still on the stairs, Francisco's computee receives a request (via
    a POI transition) to share a taxi with another resident of the hotel
    who could not find any last minute cab. Hence, the interrupt component
    is triggered and the RE transition is preferred next since the passive
    observation just introduced required a communication act on behalf of
    Francisco's computee (remember, that we have ranked RE on top of any other
    allowable transition after a POI when a communication act is required by
    the other computee). Then, the RE transition is executed
    and the computee rejects the offer since it concluded that Francisco
    should have enough cash with him (this information required calling the
    TR capability) based on an observation from the previous day about an 
    ATM transaction on Francisco's credit card account.

  - In the taxi now, as soon as Francisco mounted the PDA device on the 
    backconsole of the taxi, the computee resumed its computation where an
    AE transition for ordering the train tickets ranked higher than any other
    transition.

  - Now, the cautious-and-eff preferences weight more than any of the other 
    preferences in the cycle theory, so the AOI transition is demoted and
    thus the computee prefers to make table reservations (via means of an AE
    transitions) in a restaurant back home.

  - No sooner than the table reservations are made, new information about a 
    signal failure in the train network that causes indefinite train delays is 
    introduced via a POI transition. This, certainly invalidates the current
    plan and the preferences of the impatient pattern take effect. Thus,
    a GI transition is choosen and the GD capability suspends the goal of 
    leaving San Vincenzo in order to give higher priority to arranging a
    sightseeing tour in Rome.


References

[1] K. Stathis, The 'Leaving San Vincenzo' Scenario, SOCS Document No: 
IST32530/CITY/002/IN/PP/a1.

[2] A. Kakas and P. Moraitis. Argumentation-Based Decision Making for
Autonomous Agents, In Proceedings of AAMAS '03.

[3] M. Witkowski and K. Stathis. A Dialectic Architecture for Computational 
Autonomy. In Proceedings of AUTONOMY 2003, AAMAS, Melbourne, Australia.  

